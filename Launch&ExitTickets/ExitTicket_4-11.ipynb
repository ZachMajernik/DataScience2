{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fad371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "%config NotebookApp.iopub_msg_rate_limit=10000\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c9730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]]\n"
     ]
    }
   ],
   "source": [
    "#visualise maze:\n",
    "mazeSize = [4,12]\n",
    "\n",
    "statePositions = [[] for _ in range(mazeSize[0])]\n",
    "stateNum = 0\n",
    "for i in range(mazeSize[0]):\n",
    "    for j in range(mazeSize[1]):\n",
    "        statePositions[i].append(stateNum)\n",
    "        stateNum += 1\n",
    "        \n",
    "\n",
    "        \n",
    "giftState = 47\n",
    "            \n",
    "print(giftState)\n",
    "print(statePositions)\n",
    "\n",
    "env = gym.make(\"CliffWalking-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "091ce981",
   "metadata": {},
   "outputs": [],
   "source": [
    "qTable_1 = {}\n",
    "def resetTable():\n",
    "    global qTable_1\n",
    "    qTable_1 = {}\n",
    "    for i in range(mazeSize[0]*mazeSize[1]):\n",
    "        qTable_1[i] = [0,0,0,0] \n",
    "    global currentState\n",
    "    currentState = 36\n",
    "    \n",
    "def getPosition(state):\n",
    "    for i in range(len(statePositions)):\n",
    "        for j in range(len(statePositions[i])):\n",
    "            if statePositions[i][j] == state:\n",
    "                return i, j\n",
    "            \n",
    "def calcReward(state, nextState):\n",
    "    y1, x1 = getPosition(state)\n",
    "    y2, x2 = getPosition(nextState)\n",
    "    y3, x3 = getPosition(giftState)\n",
    "    \n",
    "    currentDist = (((y3 - y1)**2)+((x3 - x1)**2))**0.5\n",
    "    nextDist = (((y3 - y2)**2)+((x3 - x2)**2))**0.5\n",
    "    \n",
    "    changeInDist = currentDist-nextDist\n",
    "    return changeInDist/2\n",
    "\n",
    "def nextStep(state):\n",
    "    global qTable_1\n",
    "    possMoves = calcPossibleMoves(state)\n",
    "    \n",
    "    if random.random() < epsilonValue:\n",
    "        nextMove = random.choice(possMoves)\n",
    "    else:\n",
    "        qValues = {}\n",
    "        for move in possMoves:\n",
    "            qValues[move] = qTable_1[state][move]\n",
    "\n",
    "        maxValue = max(qValues.values())\n",
    "        minValue = min(qValues.values())\n",
    "        count_max = sum(1 for value in qValues.values() if value == maxValue)\n",
    "        count_min = sum(1 for value in qValues.values() if value == minValue)\n",
    "\n",
    "        if count_max > 1 and count_max < len(possMoves):\n",
    "            nextMove = random.choice([move for move in possMoves if qValues[move] != minValue])\n",
    "        elif count_max == len(possMoves):\n",
    "            nextMove = random.choice(possMoves)\n",
    "        else:\n",
    "            nextMove = max(qValues, key=qValues.get)\n",
    "    return nextMove\n",
    "\n",
    "def calcPossibleMoves(state):\n",
    "    global qTable_1\n",
    "    possibleMoves = []\n",
    "    \n",
    "    if state == 36:\n",
    "        return [0,1]\n",
    "    \n",
    "    if (state+1) % mazeSize[1] != 0:\n",
    "        possibleMoves.append(1)\n",
    "        \n",
    "    if (state+1) % mazeSize[1] != 1:\n",
    "        possibleMoves.append(3)\n",
    "        \n",
    "    if state > (mazeSize[1]-1):\n",
    "        possibleMoves.append(0)\n",
    "    \n",
    "    if state < ((mazeSize[0] * mazeSize[1]) - mazeSize[1]):\n",
    "        possibleMoves.append(2)\n",
    "        \n",
    "    return possibleMoves\n",
    "\n",
    "\n",
    "def pathFound():\n",
    "    state = 36\n",
    "    for i in range(mazeSize[0]*mazeSize[1]-1):\n",
    "        bestDirection = None\n",
    "        if max(qTable_1[state]) > 0:\n",
    "            bestDirection = qTable_1[state].index(max(qTable_1[state]))\n",
    "        newState = state\n",
    "        if bestDirection == 0 and 0 in calcPossibleMoves(state):\n",
    "            newState = state - 1\n",
    "        elif bestDirection == 1 and 1 in calcPossibleMoves(state):\n",
    "            newState = state + mazeSize[1]\n",
    "        elif bestDirection == 2 and 2 in calcPossibleMoves(state):\n",
    "            newState = state + 1\n",
    "        elif bestDirection == 3 and 3 in calcPossibleMoves(state):\n",
    "            newState = state - mazeSize[1]\n",
    "\n",
    "        if newState == giftState:\n",
    "            return True\n",
    "        state = newState\n",
    "    return False\n",
    "\n",
    "timesVisited = {}\n",
    "def resetVisited():\n",
    "    global timesVisited\n",
    "    timesVisited = {}\n",
    "    for i in range(mazeSize[0]*mazeSize[1]):\n",
    "        timesVisited[i] = 0\n",
    "\n",
    "def updateTable_qLearning(direction, nextState, reward, foundPath):\n",
    "    global qTable_1\n",
    "    global currentState\n",
    "    didConverge = False\n",
    "    updated = qTable_1[currentState][direction] + alpha*(reward + (max(qTable_1[nextState])) - qTable_1[currentState][direction])\n",
    "    changeInQ = round(abs(qTable_1[currentState][direction] - updated),5)\n",
    "    if changeInQ < convergenceThresh and changeInQ > 0:\n",
    "        if foundPath:\n",
    "            didConverge = True\n",
    "    qTable_1[currentState][direction] = updated\n",
    "    timesVisited[currentState] += 1\n",
    "    currentState = nextState\n",
    "    return didConverge, changeInQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4496b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilonValue = 0.35\n",
    "alpha = 0.65\n",
    "convergenceThresh = 0.001\n",
    "revistPenalty = -0.25\n",
    "totalTrials = 0\n",
    "currentState = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0de7654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qLearning(maxEpisodes, currentTrial):\n",
    "    global currentState\n",
    "    global revisitPenalty\n",
    "    global totalTrials\n",
    "    global totalTime_start\n",
    "    \n",
    "    firstPath = []\n",
    "    firstPathEpisode = []\n",
    "    foundFirstPath = False\n",
    "\n",
    "    currentEpisode = 1\n",
    "    converged = False\n",
    "\n",
    "    resetVisited()\n",
    "    resetTable()\n",
    "    env.reset()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while currentEpisode <= maxEpisodes:\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "        direction = nextStep(currentState)\n",
    "        if not foundFirstPath:\n",
    "            firstPath.append([currentState, direction])\n",
    "        if currentState != 47:\n",
    "            nextState, reward, terminated, truncated, info = env.step(direction)\n",
    "        \n",
    "        reward = 0\n",
    "        if terminated:\n",
    "                if nextState == 47:\n",
    "                    reward = 10\n",
    "                    if not foundFirstPath:\n",
    "                        firstPathEpisode = [currentEpisode, firstPath]\n",
    "                        foundFirstPath = True\n",
    "                else:\n",
    "                    reward = -1\n",
    "        if not terminated:\n",
    "            reward = calcReward(currentState, nextState)\n",
    "            if timesVisited[nextState] > 0:\n",
    "                reward += revistPenalty*timesVisited[nextState]\n",
    "        \n",
    "        converged, changeInQ = updateTable_qLearning(direction, nextState, reward, foundFirstPath)\n",
    "\n",
    "        if terminated or truncated or converged:\n",
    "            observation, info = env.reset()\n",
    "            currentState = 36\n",
    "            if not converged:\n",
    "                currentEpisode += 1\n",
    "            if not foundFirstPath:\n",
    "                firstPath = []\n",
    "            resetVisited()\n",
    "\n",
    "\n",
    "        if converged:\n",
    "            end_time = time.time()\n",
    "        \n",
    "        time.sleep(0.002)\n",
    "        clear_output(wait=True)\n",
    "        if totalTrials != 0:\n",
    "            print(\"Trial: \" + 'Q-Learning, ' + 'trialType '+ str(trialType) + ', Trial ' + str(currentTrial) + \"/\" + str(totalTrials))\n",
    "        print(\"Episode: \" + str(currentEpisode) + \"/\" + str(maxEpisodes))\n",
    "        print(\"Trial Time: \" + str(round(time.time()-start_time, 3)) + \" sec\")\n",
    "        print(currentState)\n",
    "        if totalTrials != 0:\n",
    "            print(\"Total Time: \" + str(round((time.time()-totalTime_start)/60, 3)) + \" min\")\n",
    "        print(\"Q-Table:\")\n",
    "        for i in range(len(qTable_1)):\n",
    "            print(str(i) + \": \" + str(qTable_1[i]))\n",
    "        print(\"change in Q: \" + str(changeInQ))\n",
    "        \n",
    "    duration = 0\n",
    "    if converged:\n",
    "        duration = end_time - start_time\n",
    "        print(str(round(duration, 3)) + \" seconds to converge\")\n",
    "    else:\n",
    "        duration = None\n",
    "        print(\"No convergence\")\n",
    "        \n",
    "    return (currentEpisode-1), duration, firstPathEpisode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cc82d0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6/2000\n",
      "Trial Time: 1.141 sec\n",
      "36\n",
      "Q-Table:\n",
      "0: [0, 0.7306347083845248, 0, 0]\n",
      "1: [0, 0.6433295264742394, 0, -5.79557263281294e-05]\n",
      "2: [0, 0.7400526980366546, -0.7658875541037989, -0.3098788967317591]\n",
      "3: [0, 0.9090763751634257, -0.7752423431971139, -0.6451186510051807]\n",
      "4: [0, 1.1380736528910773, -0.5596027637240374, -0.3016749578224271]\n",
      "5: [0, 1.059462407237795, -0.4324929551331752, -0.45745998134347526]\n",
      "6: [0, 0.8388624945414902, 0, -0.28510691223757234]\n",
      "7: [0, 0.7572196869787384, 0.18716636329582798, 0]\n",
      "8: [0, -0.07698789843471257, 0.6775007648807323, 0]\n",
      "9: [0, 0, 0.45876414924023706, -0.538228244403053]\n",
      "10: [0, 0, 0, 0.013087644560225481]\n",
      "11: [0, 0, 0, 0]\n",
      "12: [-0.0719596681350398, 0.4357213326642657, 0, 0]\n",
      "13: [0.01705935131502435, -0.7184814510385465, -0.047568825790096435, -0.274236722860647]\n",
      "14: [-0.1663848399325755, -0.7737419902403947, -0.7582798628605907, -0.48493770222910115]\n",
      "15: [-0.8723884242473658, -0.14369046150105097, -0.4257364103339635, -0.752049944157757]\n",
      "16: [0.12638781777331123, 0.011231430961608613, -0.7445613248401112, -0.963982942635311]\n",
      "17: [0.21157712767162512, -0.141221832512143, -0.6007884133705907, -0.3105552349067217]\n",
      "18: [-0.14488080350600904, 0.23809140887419797, 0, -1.3755989056836215]\n",
      "19: [-0.17155581462513664, 0.5281852893597878, -0.009362942983683037, -0.5913570319303476]\n",
      "20: [-0.6909580427773163, 0.3266492515063931, 0.44542843665186194, 0]\n",
      "21: [-0.08839787214414961, 0.38761832614894665, 0, 0]\n",
      "22: [-0.30101814686729167, 5.060976406482244, 0, -0.20966659709949464]\n",
      "23: [0, 0, 9.35195625, 0]\n",
      "24: [0.3136683317434546, 0.5256244512273283, -0.2563478537090892, 0]\n",
      "25: [0, 0.8508358950243449, -1.9218346587452602, -0.35587106188798256]\n",
      "26: [-0.8023984831067628, 0.6061482360793645, 0, -0.4581924302687148]\n",
      "27: [-0.3847848884544509, 0.3361280422149413, 0, -0.6411289494944368]\n",
      "28: [-0.03438322898933206, -0.6336551542603647, -2.1706939975440225, -0.9721367293407489]\n",
      "29: [-0.4310865866294093, 0.10661724857950952, -2.5393129398316563, -0.5755969040223965]\n",
      "30: [-0.09299722040105876, -0.007827986408084731, -2.730318658082345, 0]\n",
      "31: [-0.7285806270376414, 0, 0, -0.4796720135919153]\n",
      "32: [0, 0.5197703998915398, 0, 0]\n",
      "33: [0, 4.129020288629623, 0, -0.22005129767876286]\n",
      "34: [-0.21723332466934517, 8.399361200491196, -5.065380592228744, -0.8367658565180127]\n",
      "35: [2.7064375000000003, 0, 9.947478125, 0]\n",
      "36: [0.4267974164478343, -1.9783464287826003, 0, 0]\n",
      "37: [0, 0, 0, 0]\n",
      "38: [0, 0, 0, 0]\n",
      "39: [0, 0, 0, 0]\n",
      "40: [0, 0, 0, 0]\n",
      "41: [0, 0, 0, 0]\n",
      "42: [0, 0, 0, 0]\n",
      "43: [0, 0, 0, 0]\n",
      "44: [0, 0, 0, 0]\n",
      "45: [0, 0, 0, 0]\n",
      "46: [0, 0, 0, 0]\n",
      "47: [0, 0, 0, 0]\n",
      "change in Q: 6e-05\n",
      "1.137 seconds to converge\n"
     ]
    }
   ],
   "source": [
    "episodes, duration, firstPath = qLearning(2000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5cf80413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24cf46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
